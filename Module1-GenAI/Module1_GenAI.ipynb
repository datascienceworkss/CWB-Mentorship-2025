{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Requirements"
      ],
      "metadata": {
        "id": "pFvlBuQWq4lY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Jn3BnmwbIQY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5af53d50-11cc-4b37-abb1-7613cfebb06c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.59)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.42)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.4)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (4.13.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-5.5.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Downloading pypdf-5.5.0-py3-none-any.whl (303 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m303.4/303.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-5.5.0\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.24-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.59 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.59)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.25 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.25)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.42)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.25->langchain_community) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.25->langchain_community) (2.11.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain_community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain_community) (4.13.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.59->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain_community) (2.33.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.3.1)\n",
            "Downloading langchain_community-0.3.24-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain_community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain_community-0.3.24 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.9.1 python-dotenv-1.1.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain\n",
        "!pip install pypdf\n",
        "!pip install langchain_community"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Document Loading"
      ],
      "metadata": {
        "id": "urJ_2KsTq-eD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-dMt6EKMI9O6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WWmiV7SKJGko"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load PDF using pypdf into array of documents, where each document contains the page content and metadata with page number."
      ],
      "metadata": {
        "id": "vImtISFCqtKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader(\"/paul_graham_essay.pdf\")\n",
        "pages = loader.load()"
      ],
      "metadata": {
        "id": "e7IdZYvOlmm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(pages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QU0ivgp1mZYA",
        "outputId": "26c92786-e604-4bfd-8998-5df73b262bb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pages[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ItKCblfKmZ4",
        "outputId": "d45d8119-e77b-4c59-e3ae-c16e3de012d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'producer': 'LibreOffice 7.3', 'creator': 'Writer', 'creationdate': '2024-06-14T16:51:51+00:00', 'source': '/paul_graham_essay.pdf', 'total_pages': 20, 'page': 0, 'page_label': '1'}, page_content='What I Worked On\\nFebruary 2021\\nBefore college the two main things I worked on, outside of school, were writing \\nand programming. I didn\\'t write essays. I wrote what beginning writers were \\nsupposed to write then, and probably still are: short stories. My stories were \\nawful. They had hardly any plot, just characters with strong feelings, which I \\nimagined made them deep.\\nThe first programs I tried writing were on the IBM 1401 that our school district\\nused for what was then called \"data processing.\" This was in 9th grade, so I was\\n13 or 14. The school district\\'s 1401 happened to be in the basement of our \\njunior high school, and my friend Rich Draves and I got permission to use it. It\\nwas like a mini Bond villain\\'s lair down there, with all these alien-looking \\nmachines — CPU, disk drives, printer, card reader — sitting up on a raised floor\\nunder bright fluorescent lights.\\nThe language we used was an early version of Fortran. You had to type programs \\non punch cards, then stack them in the card reader and press a button to load \\nthe program into memory and run it. The result would ordinarily be to print \\nsomething on the spectacularly loud printer.\\nI was puzzled by the 1401. I couldn\\'t figure out what to do with it. And in \\nretrospect there\\'s not much I could have done with it. The only form of input to\\nprograms was data stored on punched cards, and I didn\\'t have any data stored on \\npunched cards. The only other option was to do things that didn\\'t rely on any \\ninput, like calculate approximations of pi, but I didn\\'t know enough math to do \\nanything interesting of that type. So I\\'m not surprised I can\\'t remember any \\nprograms I wrote, because they can\\'t have done much. My clearest memory is of \\nthe moment I learned it was possible for programs not to terminate, when one of \\nmine didn\\'t. On a machine without time-sharing, this was a social as well as a \\ntechnical error, as the data center manager\\'s expression made clear.\\nWith microcomputers, everything changed. Now you could have a computer sitting \\nright in front of you, on a desk, that could respond to your keystrokes as it \\nwas running instead of just churning through a stack of punch cards and then \\nstopping. [1]\\nThe first of my friends to get a microcomputer built it himself. It was sold as \\na kit by Heathkit. I remember vividly how impressed and envious I felt watching \\nhim sitting in front of it, typing programs right into the computer.\\nComputers were expensive in those days and it took me years of nagging before I \\nconvinced my father to buy one, a TRS-80, in about 1980. The gold standard then \\nwas the Apple II, but a TRS-80 was good enough. This was when I really started \\nprogramming. I wrote simple games, a program to predict how high my model \\nrockets would fly, and a word processor that my father used to write at least \\none book. There was only room in memory for about 2 pages of text, so he\\'d write\\n2 pages at a time and then print them out, but it was a lot better than a \\ntypewriter.\\nThough I liked programming, I didn\\'t plan to study it in college. In college I \\nwas going to study philosophy, which sounded much more powerful. It seemed, to \\nmy naive high school self, to be the study of the ultimate truths, compared to \\nwhich the things studied in other fields would be mere domain knowledge. What I \\ndiscovered when I got to college was that the other fields took up so much of \\nthe space of ideas that there wasn\\'t much left for these supposed ultimate \\ntruths. All that seemed left for philosophy were edge cases that people in other\\nfields felt could safely be ignored.\\nI couldn\\'t have put this into words when I was 18. All I knew at the time was')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pages[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjanof3FKXWT",
        "outputId": "9d8bef6f-89e1-4518-db2e-1766ac0ece08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'producer': 'LibreOffice 7.3', 'creator': 'Writer', 'creationdate': '2024-06-14T16:51:51+00:00', 'source': '/paul_graham_essay.pdf', 'total_pages': 20, 'page': 1, 'page_label': '2'}, page_content='that I kept taking philosophy courses and they kept being boring. So I decided \\nto switch to AI.\\nAI was in the air in the mid 1980s, but there were two things especially that \\nmade me want to work on it: a novel by Heinlein called The Moon is a Harsh \\nMistress, which featured an intelligent computer called Mike, and a PBS \\ndocumentary that showed Terry Winograd using SHRDLU. I haven\\'t tried rereading \\nThe Moon is a Harsh Mistress, so I don\\'t know how well it has aged, but when I \\nread it I was drawn entirely into its world. It seemed only a matter of time \\nbefore we\\'d have Mike, and when I saw Winograd using SHRDLU, it seemed like that\\ntime would be a few years at most. All you had to do was teach SHRDLU more \\nwords.\\nThere weren\\'t any classes in AI at Cornell then, not even graduate classes, so I\\nstarted trying to teach myself. Which meant learning Lisp, since in those days \\nLisp was regarded as the language of AI. The commonly used programming languages\\nthen were pretty primitive, and programmers\\' ideas correspondingly so. The \\ndefault language at Cornell was a Pascal-like language called PL/I, and the \\nsituation was similar elsewhere. Learning Lisp expanded my concept of a program \\nso fast that it was years before I started to have a sense of where the new \\nlimits were. This was more like it; this was what I had expected college to do. \\nIt wasn\\'t happening in a class, like it was supposed to, but that was ok. For \\nthe next couple years I was on a roll. I knew what I was going to do.\\nFor my undergraduate thesis, I reverse-engineered SHRDLU. My God did I love \\nworking on that program. It was a pleasing bit of code, but what made it even \\nmore exciting was my belief — hard to imagine now, but not unique in 1985 — that\\nit was already climbing the lower slopes of intelligence.\\nI had gotten into a program at Cornell that didn\\'t make you choose a major. You \\ncould take whatever classes you liked, and choose whatever you liked to put on \\nyour degree. I of course chose \"Artificial Intelligence.\" When I got the actual \\nphysical diploma, I was dismayed to find that the quotes had been included, \\nwhich made them read as scare-quotes. At the time this bothered me, but now it \\nseems amusingly accurate, for reasons I was about to discover.\\nI applied to 3 grad schools: MIT and Yale, which were renowned for AI at the \\ntime, and Harvard, which I\\'d visited because Rich Draves went there, and was \\nalso home to Bill Woods, who\\'d invented the type of parser I used in my SHRDLU \\nclone. Only Harvard accepted me, so that was where I went.\\nI don\\'t remember the moment it happened, or if there even was a specific moment,\\nbut during the first year of grad school I realized that AI, as practiced at the\\ntime, was a hoax. By which I mean the sort of AI in which a program that\\'s told \\n\"the dog is sitting on the chair\" translates this into some formal \\nrepresentation and adds it to the list of things it knows.\\nWhat these programs really showed was that there\\'s a subset of natural language \\nthat\\'s a formal language. But a very proper subset. It was clear that there was \\nan unbridgeable gap between what they could do and actually understanding \\nnatural language. It was not, in fact, simply a matter of teaching SHRDLU more \\nwords. That whole way of doing AI, with explicit data structures representing \\nconcepts, was not going to work. Its brokenness did, as so often happens, \\ngenerate a lot of opportunities to write papers about various band-aids that \\ncould be applied to it, but it was never going to get us Mike.\\nSo I looked around to see what I could salvage from the wreckage of my plans, \\nand there was Lisp. I knew from experience that Lisp was interesting for its own\\nsake and not just for its association with AI, even though that was the main \\nreason people cared about it at the time. So I decided to focus on Lisp. In \\nfact, I decided to write a book about Lisp hacking. It\\'s scary to think how \\nlittle I knew about Lisp hacking when I started writing that book. But there\\'s \\nnothing like writing a book about something to help you learn it. The book, On \\nLisp, wasn\\'t published till 1993, but I wrote much of it in grad school.')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "1AYLmbtFJ1zc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pages[5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uR1mmlhVdpEG",
        "outputId": "bc4d6c96-9fd7-41b1-9a16-45e442361416"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='Combinator, is that the low end eats the high end: that it\\'s good to be the \\n\"entry level\" option, even though that will be less prestigious, because if \\nyou\\'re not, someone else will be, and will squash you against the ceiling. Which\\nin turn means that prestige is a danger sign.\\nWhen I left to go back to RISD the next fall, I arranged to do freelance work \\nfor the group that did projects for customers, and this was how I survived for \\nthe next several years. When I came back to visit for a project later on, \\nsomeone told me about a new thing called HTML, which was, as he described it, a \\nderivative of SGML. Markup language enthusiasts were an occupational hazard at \\nInterleaf and I ignored him, but this HTML thing later became a big part of my \\nlife.\\nIn the fall of 1992 I moved back to Providence to continue at RISD. The \\nfoundation had merely been intro stuff, and the Accademia had been a (very \\ncivilized) joke. Now I was going to see what real art school was like. But alas \\nit was more like the Accademia than not. Better organized, certainly, and a lot \\nmore expensive, but it was now becoming clear that art school did not bear the \\nsame relationship to art that medical school bore to medicine. At least not the \\npainting department. The textile department, which my next door neighbor \\nbelonged to, seemed to be pretty rigorous. No doubt illustration and \\narchitecture were too. But painting was post-rigorous. Painting students were \\nsupposed to express themselves, which to the more worldly ones meant to try to \\ncook up some sort of distinctive signature style.\\nA signature style is the visual equivalent of what in show business is known as \\na \"schtick\": something that immediately identifies the work as yours and no one \\nelse\\'s. For example, when you see a painting that looks like a certain kind of \\ncartoon, you know it\\'s by Roy Lichtenstein. So if you see a big painting of this\\ntype hanging in the apartment of a hedge fund manager, you know he paid millions\\nof dollars for it. That\\'s not always why artists have a signature style, but \\nit\\'s usually why buyers pay a lot for such work. [6]\\nThere were plenty of earnest students too: kids who \"could draw\" in high school,\\nand now had come to what was supposed to be the best art school in the country, \\nto learn to draw even better. They tended to be confused and demoralized by what\\nthey found at RISD, but they kept going, because painting was what they did. I \\nwas not one of the kids who could draw in high school, but at RISD I was \\ndefinitely closer to their tribe than the tribe of signature style seekers.\\nI learned a lot in the color class I took at RISD, but otherwise I was basically\\nteaching myself to paint, and I could do that for free. So in 1993 I dropped \\nout. I hung around Providence for a bit, and then my college friend Nancy Parmet\\ndid me a big favor. A rent-controlled apartment in a building her mother owned \\nin New York was becoming vacant. Did I want it? It wasn\\'t much more than my \\ncurrent place, and New York was supposed to be where the artists were. So yes, I\\nwanted it! [7]\\nAsterix comics begin by zooming in on a tiny corner of Roman Gaul that turns out\\nnot to be controlled by the Romans. You can do something similar on a map of New\\nYork City: if you zoom in on the Upper East Side, there\\'s a tiny corner that\\'s \\nnot rich, or at least wasn\\'t in 1993. It\\'s called Yorkville, and that was my new\\nhome. Now I was a New York artist — in the strictly technical sense of making \\npaintings and living in New York.\\nI was nervous about money, because I could sense that Interleaf was on the way \\ndown. Freelance Lisp hacking work was very rare, and I didn\\'t want to have to \\nprogram in another language, which in those days would have meant C++ if I was \\nlucky. So with my unerring nose for financial opportunity, I decided to write \\nanother book on Lisp. This would be a popular book, the sort of book that could \\nbe used as a textbook. I imagined myself living frugally off the royalties and \\nspending all my time painting. (The painting on the cover of this book, ANSI \\nCommon Lisp, is one that I painted around this time.)', metadata={'source': 'paul_graham_essay.pdf', 'page': 5})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "An advantage of this approach is that documents can be retrieved with page numbers."
      ],
      "metadata": {
        "id": "gnBBYSWPrl-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pages[0].metadata[\"source\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "8SdMvICMK4nH",
        "outputId": "9f19d8dd-512b-4e1a-8dfc-1f5e92c69dc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/paul_graham_essay.pdf'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pages[0].page_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "3zliaQvRd7ZF",
        "outputId": "11b2a695-adbf-493b-e30b-0321f8be0804"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'What I Worked On\\nFebruary 2021\\nBefore college the two main things I worked on, outside of school, were writing \\nand programming. I didn\\'t write essays. I wrote what beginning writers were \\nsupposed to write then, and probably still are: short stories. My stories were \\nawful. They had hardly any plot, just characters with strong feelings, which I \\nimagined made them deep.\\nThe first programs I tried writing were on the IBM 1401 that our school district\\nused for what was then called \"data processing.\" This was in 9th grade, so I was\\n13 or 14. The school district\\'s 1401 happened to be in the basement of our \\njunior high school, and my friend Rich Draves and I got permission to use it. It\\nwas like a mini Bond villain\\'s lair down there, with all these alien-looking \\nmachines — CPU, disk drives, printer, card reader — sitting up on a raised floor\\nunder bright fluorescent lights.\\nThe language we used was an early version of Fortran. You had to type programs \\non punch cards, then stack them in the card reader and press a button to load \\nthe program into memory and run it. The result would ordinarily be to print \\nsomething on the spectacularly loud printer.\\nI was puzzled by the 1401. I couldn\\'t figure out what to do with it. And in \\nretrospect there\\'s not much I could have done with it. The only form of input to\\nprograms was data stored on punched cards, and I didn\\'t have any data stored on \\npunched cards. The only other option was to do things that didn\\'t rely on any \\ninput, like calculate approximations of pi, but I didn\\'t know enough math to do \\nanything interesting of that type. So I\\'m not surprised I can\\'t remember any \\nprograms I wrote, because they can\\'t have done much. My clearest memory is of \\nthe moment I learned it was possible for programs not to terminate, when one of \\nmine didn\\'t. On a machine without time-sharing, this was a social as well as a \\ntechnical error, as the data center manager\\'s expression made clear.\\nWith microcomputers, everything changed. Now you could have a computer sitting \\nright in front of you, on a desk, that could respond to your keystrokes as it \\nwas running instead of just churning through a stack of punch cards and then \\nstopping. [1]\\nThe first of my friends to get a microcomputer built it himself. It was sold as \\na kit by Heathkit. I remember vividly how impressed and envious I felt watching \\nhim sitting in front of it, typing programs right into the computer.\\nComputers were expensive in those days and it took me years of nagging before I \\nconvinced my father to buy one, a TRS-80, in about 1980. The gold standard then \\nwas the Apple II, but a TRS-80 was good enough. This was when I really started \\nprogramming. I wrote simple games, a program to predict how high my model \\nrockets would fly, and a word processor that my father used to write at least \\none book. There was only room in memory for about 2 pages of text, so he\\'d write\\n2 pages at a time and then print them out, but it was a lot better than a \\ntypewriter.\\nThough I liked programming, I didn\\'t plan to study it in college. In college I \\nwas going to study philosophy, which sounded much more powerful. It seemed, to \\nmy naive high school self, to be the study of the ultimate truths, compared to \\nwhich the things studied in other fields would be mere domain knowledge. What I \\ndiscovered when I got to college was that the other fields took up so much of \\nthe space of ideas that there wasn\\'t much left for these supposed ultimate \\ntruths. All that seemed left for philosophy were edge cases that people in other\\nfields felt could safely be ignored.\\nI couldn\\'t have put this into words when I was 18. All I knew at the time was'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Splitters"
      ],
      "metadata": {
        "id": "nWauPuDkrsru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "id": "QYOv-Wyfr1jw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=100,\n",
        "    chunk_overlap=20,\n",
        "    length_function=len,\n",
        "    is_separator_regex=False,\n",
        ")"
      ],
      "metadata": {
        "id": "czlZRJq2r2TT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[\"\\n\\n\", \"\\n\", \" \", \"\",]"
      ],
      "metadata": {
        "id": "ffK3nv5GfbrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split the text into chunks"
      ],
      "metadata": {
        "id": "BEU02TdlteGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chunks = []\n",
        "for page in pages:\n",
        "    page_text = page.page_content\n",
        "    page_chunks = text_splitter.split_text(page_text)\n",
        "    chunks.extend(page_chunks)"
      ],
      "metadata": {
        "id": "L0TLTHtkr8Ig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Print Top 5 chunks"
      ],
      "metadata": {
        "id": "ry1uE_r4tagd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, chunk in enumerate(chunks):\n",
        "   if i<10:\n",
        "      print(f\"Chunk {i + 1}:\")\n",
        "      print(chunk)\n",
        "      print(\"\\n\")\n",
        "      i=i+1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7QwUf4rsBIV",
        "outputId": "a37e75d9-582b-4940-8627-d207a660f627"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunk 1:\n",
            "What I Worked On\n",
            "February 2021\n",
            "\n",
            "\n",
            "Chunk 2:\n",
            "February 2021\n",
            "Before college the two main things I worked on, outside of school, were writing\n",
            "\n",
            "\n",
            "Chunk 3:\n",
            "and programming. I didn't write essays. I wrote what beginning writers were\n",
            "\n",
            "\n",
            "Chunk 4:\n",
            "supposed to write then, and probably still are: short stories. My stories were\n",
            "\n",
            "\n",
            "Chunk 5:\n",
            "awful. They had hardly any plot, just characters with strong feelings, which I\n",
            "\n",
            "\n",
            "Chunk 6:\n",
            "imagined made them deep.\n",
            "\n",
            "\n",
            "Chunk 7:\n",
            "The first programs I tried writing were on the IBM 1401 that our school district\n",
            "\n",
            "\n",
            "Chunk 8:\n",
            "used for what was then called \"data processing.\" This was in 9th grade, so I was\n",
            "\n",
            "\n",
            "Chunk 9:\n",
            "13 or 14. The school district's 1401 happened to be in the basement of our\n",
            "\n",
            "\n",
            "Chunk 10:\n",
            "junior high school, and my friend Rich Draves and I got permission to use it. It\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "internal Architecture"
      ],
      "metadata": {
        "id": "2kh_FDxkgqcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunk in english ---> vector\n",
        "What I Worked On February 2021 ---> [0.1,0.4,0.6,0.8,....]"
      ],
      "metadata": {
        "id": "s7dt29mGgRRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store in vector db -> chunk, embedding --> What I Worked On February 2021 ---> [0.1,0.4,0.6,0.8,....]"
      ],
      "metadata": {
        "id": "X2d_xHtDge_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Congratulations you completed Module-1 !!"
      ],
      "metadata": {
        "id": "II8mTmR7tquJ"
      }
    }
  ]
}